{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f8a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-----------------------------------------------------------------------------\n",
    "Transformer using pytorch and numpy\n",
    "-----------------------------------------------------------------------------\n",
    "AUTHOR: Soumitra Samanta (soumitra.samanta@gm.rkmvu.ac.in)\n",
    "-----------------------------------------------------------------------------\n",
    "Package required:\n",
    "Numpy: https://numpy.org/\n",
    "Matplotlib: https://matplotlib.org\n",
    "-----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d4aa92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Self-attention layer models is: \n",
      "self_attention_layer(\n",
      "  (W_q_): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (W_k_): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (W_v_): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------------\n",
      "Self-attention layer input size: torch.Size([5, 100, 10])\n",
      "Self-attention layer output size: torch.Size([5, 100, 10])\n",
      "----------------------------------------------------------------------\n",
      "======================================================================\n",
      "Transformer block models is: \n",
      "transformer_block_encoder(\n",
      "  (attention_): self_attention_layer(\n",
      "    (W_q_): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (W_k_): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (W_v_): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      "  (layer_norm1_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "  (layer_norm2_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "  (ffnn_): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      "  (droput_ops_): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "----------------------------------------------------------------------\n",
      "Transformer block models summary:\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 100, 10]             110\n",
      "            Linear-2              [-1, 100, 10]             110\n",
      "            Linear-3              [-1, 100, 10]             110\n",
      "self_attention_layer-4              [-1, 100, 10]               0\n",
      "           Dropout-5              [-1, 100, 10]               0\n",
      "         LayerNorm-6              [-1, 100, 10]              20\n",
      "            Linear-7            [-1, 100, 1024]          11,264\n",
      "              ReLU-8            [-1, 100, 1024]               0\n",
      "            Linear-9              [-1, 100, 10]          10,250\n",
      "          Dropout-10              [-1, 100, 10]               0\n",
      "        LayerNorm-11              [-1, 100, 10]              20\n",
      "================================================================\n",
      "Total params: 21,884\n",
      "Trainable params: 21,884\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.63\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 1.72\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Transformer block input size: torch.Size([5, 100, 10])\n",
      "Transformer block output size: torch.Size([5, 100, 10])\n",
      "----------------------------------------------------------------------\n",
      "======================================================================\n",
      "Transformer encoder models is: \n",
      "transformer_encoder(\n",
      "  (trs_endr_blocks_): ModuleList(\n",
      "    (0-1): 2 x transformer_block_encoder(\n",
      "      (attention_): self_attention_layer(\n",
      "        (W_q_): Linear(in_features=10, out_features=10, bias=True)\n",
      "        (W_k_): Linear(in_features=10, out_features=10, bias=True)\n",
      "        (W_v_): Linear(in_features=10, out_features=10, bias=True)\n",
      "      )\n",
      "      (layer_norm1_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm2_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffnn_): Sequential(\n",
      "        (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "      )\n",
      "      (droput_ops_): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------------\n",
      "Transformer encoder models summary:\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 100, 10]             110\n",
      "            Linear-2              [-1, 100, 10]             110\n",
      "            Linear-3              [-1, 100, 10]             110\n",
      "self_attention_layer-4              [-1, 100, 10]               0\n",
      "           Dropout-5              [-1, 100, 10]               0\n",
      "         LayerNorm-6              [-1, 100, 10]              20\n",
      "            Linear-7            [-1, 100, 1024]          11,264\n",
      "              ReLU-8            [-1, 100, 1024]               0\n",
      "            Linear-9              [-1, 100, 10]          10,250\n",
      "          Dropout-10              [-1, 100, 10]               0\n",
      "        LayerNorm-11              [-1, 100, 10]              20\n",
      "transformer_block_encoder-12              [-1, 100, 10]               0\n",
      "           Linear-13              [-1, 100, 10]             110\n",
      "           Linear-14              [-1, 100, 10]             110\n",
      "           Linear-15              [-1, 100, 10]             110\n",
      "self_attention_layer-16              [-1, 100, 10]               0\n",
      "          Dropout-17              [-1, 100, 10]               0\n",
      "        LayerNorm-18              [-1, 100, 10]              20\n",
      "           Linear-19            [-1, 100, 1024]          11,264\n",
      "             ReLU-20            [-1, 100, 1024]               0\n",
      "           Linear-21              [-1, 100, 10]          10,250\n",
      "          Dropout-22              [-1, 100, 10]               0\n",
      "        LayerNorm-23              [-1, 100, 10]              20\n",
      "transformer_block_encoder-24              [-1, 100, 10]               0\n",
      "================================================================\n",
      "Total params: 43,768\n",
      "Trainable params: 43,768\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.28\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 3.45\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Transformer encoder input size: torch.Size([5, 100, 10])\n",
      "Transformer encoder output size: torch.Size([5, 100, 10])\n",
      "----------------------------------------------------------------------\n",
      "======================================================================\n",
      "Cross-attention layer models is: \n",
      "cross_attention_layer(\n",
      "  (W_q_): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (W_k_): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (W_v_): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------------\n",
      "Cross-attention layer input size: torch.Size([5, 100, 10])\n",
      "Cross-attention layer output size: torch.Size([5, 100, 10])\n",
      "----------------------------------------------------------------------\n",
      "======================================================================\n",
      "Transformer decoder block models is: \n",
      "transformer_block_decoder(\n",
      "  (attention_): self_attention_layer(\n",
      "    (W_q_): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (W_k_): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (W_v_): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      "  (cross_attention_): cross_attention_layer(\n",
      "    (W_q_): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (W_k_): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (W_v_): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      "  (layer_norm1_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "  (layer_norm2_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "  (layer_norm3_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "  (ffnn_): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      "  (droput_ops_): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "----------------------------------------------------------------------\n",
      "Transformer decoder block models summary:\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 100, 10]             110\n",
      "            Linear-2              [-1, 100, 10]             110\n",
      "            Linear-3              [-1, 100, 10]             110\n",
      "self_attention_layer-4              [-1, 100, 10]               0\n",
      "           Dropout-5              [-1, 100, 10]               0\n",
      "         LayerNorm-6              [-1, 100, 10]              20\n",
      "            Linear-7              [-1, 100, 10]             110\n",
      "            Linear-8              [-1, 100, 10]             110\n",
      "            Linear-9              [-1, 100, 10]             110\n",
      "cross_attention_layer-10              [-1, 100, 10]               0\n",
      "          Dropout-11              [-1, 100, 10]               0\n",
      "        LayerNorm-12              [-1, 100, 10]              20\n",
      "           Linear-13            [-1, 100, 1024]          11,264\n",
      "             ReLU-14            [-1, 100, 1024]               0\n",
      "           Linear-15              [-1, 100, 10]          10,250\n",
      "          Dropout-16              [-1, 100, 10]               0\n",
      "        LayerNorm-17              [-1, 100, 10]              20\n",
      "================================================================\n",
      "Total params: 22,234\n",
      "Trainable params: 22,234\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.81\n",
      "Forward/backward pass size (MB): 1.68\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 5.58\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Transformer block input size: torch.Size([5, 100, 10])\n",
      "Transformer block output size: torch.Size([5, 100, 10])\n",
      "----------------------------------------------------------------------\n",
      "======================================================================\n",
      "Transformer decoder models is: \n",
      "transformer_decoder(\n",
      "  (trs_dcdr_blocks_): ModuleList(\n",
      "    (0-1): 2 x transformer_block_decoder(\n",
      "      (attention_): self_attention_layer(\n",
      "        (W_q_): Linear(in_features=10, out_features=10, bias=True)\n",
      "        (W_k_): Linear(in_features=10, out_features=10, bias=True)\n",
      "        (W_v_): Linear(in_features=10, out_features=10, bias=True)\n",
      "      )\n",
      "      (cross_attention_): cross_attention_layer(\n",
      "        (W_q_): Linear(in_features=10, out_features=10, bias=True)\n",
      "        (W_k_): Linear(in_features=10, out_features=10, bias=True)\n",
      "        (W_v_): Linear(in_features=10, out_features=10, bias=True)\n",
      "      )\n",
      "      (layer_norm1_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm2_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm3_): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffnn_): Sequential(\n",
      "        (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "      )\n",
      "      (droput_ops_): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------------\n",
      "Transformer decoder models summary:\n",
      "----------------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 100, 10]             110\n",
      "            Linear-2              [-1, 100, 10]             110\n",
      "            Linear-3              [-1, 100, 10]             110\n",
      "self_attention_layer-4              [-1, 100, 10]               0\n",
      "           Dropout-5              [-1, 100, 10]               0\n",
      "         LayerNorm-6              [-1, 100, 10]              20\n",
      "            Linear-7              [-1, 100, 10]             110\n",
      "            Linear-8              [-1, 100, 10]             110\n",
      "            Linear-9              [-1, 100, 10]             110\n",
      "cross_attention_layer-10              [-1, 100, 10]               0\n",
      "          Dropout-11              [-1, 100, 10]               0\n",
      "        LayerNorm-12              [-1, 100, 10]              20\n",
      "           Linear-13            [-1, 100, 1024]          11,264\n",
      "             ReLU-14            [-1, 100, 1024]               0\n",
      "           Linear-15              [-1, 100, 10]          10,250\n",
      "          Dropout-16              [-1, 100, 10]               0\n",
      "        LayerNorm-17              [-1, 100, 10]              20\n",
      "transformer_block_decoder-18              [-1, 100, 10]               0\n",
      "           Linear-19              [-1, 100, 10]             110\n",
      "           Linear-20              [-1, 100, 10]             110\n",
      "           Linear-21              [-1, 100, 10]             110\n",
      "self_attention_layer-22              [-1, 100, 10]               0\n",
      "          Dropout-23              [-1, 100, 10]               0\n",
      "        LayerNorm-24              [-1, 100, 10]              20\n",
      "           Linear-25              [-1, 100, 10]             110\n",
      "           Linear-26              [-1, 100, 10]             110\n",
      "           Linear-27              [-1, 100, 10]             110\n",
      "cross_attention_layer-28              [-1, 100, 10]               0\n",
      "          Dropout-29              [-1, 100, 10]               0\n",
      "        LayerNorm-30              [-1, 100, 10]              20\n",
      "           Linear-31            [-1, 100, 1024]          11,264\n",
      "             ReLU-32            [-1, 100, 1024]               0\n",
      "           Linear-33              [-1, 100, 10]          10,250\n",
      "          Dropout-34              [-1, 100, 10]               0\n",
      "        LayerNorm-35              [-1, 100, 10]              20\n",
      "transformer_block_decoder-36              [-1, 100, 10]               0\n",
      "================================================================\n",
      "Total params: 44,468\n",
      "Trainable params: 44,468\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.81\n",
      "Forward/backward pass size (MB): 3.37\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 7.35\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n",
      "Transformer decoder input size: torch.Size([5, 100, 10])\n",
      "Transformer decoder output size: torch.Size([5, 100, 10])\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class self_attention_layer(nn.Module):\n",
    "    \"\"\"\n",
    "    Self attention layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dims_embd: int,\n",
    "    )->None:\n",
    "        \"\"\"\n",
    "        Self attention class initialization\n",
    "        \n",
    "        Inpout:\n",
    "            - dims_embd (int): Embedding dimension\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.dims_embd_ = dims_embd\n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        self.W_q_ = nn.Linear(dims_embd, dims_embd)\n",
    "        self.W_k_ = nn.Linear(dims_embd, dims_embd)\n",
    "        self.W_v_ = nn.Linear(dims_embd, dims_embd)\n",
    "        \n",
    "        \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        x: Tensor \n",
    "    )->Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the self attention layer\n",
    "        \n",
    "        Imput:\n",
    "            - x (torch tensor): Input data\n",
    "            \n",
    "        Output:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        y = []\n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        Q=self.W_q_(x)\n",
    "        K=self.W_k_(x)\n",
    "        V=self.W_v_(x)\n",
    "\n",
    "        attn_scores=torch.matmul(Q,K.transpose(-2,-1))/torch.sqrt(torch.tensor(self.dims_embd_))\n",
    "        attn_scores=F.softmax(attn_scores,dim=-1)\n",
    "        y=torch.matmul(attn_scores,V)\n",
    "        \n",
    "        \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "    \n",
    "        return y\n",
    "    \n",
    "class transformer_block_encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer single block\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dims_embd: int,\n",
    "        num_hidden_nodes_ffnn: int = 2048,\n",
    "        dropout_prob: float = 0.0\n",
    "    )->None:\n",
    "        \"\"\"\n",
    "        Transformer single block class initialization\n",
    "        \n",
    "        Inpout:\n",
    "            - dims_embd (int):             Embedding dimension\n",
    "            - num_hidden_nodes_ffnn (int): Number of neurons in the fed-forward layer\n",
    "            - dropout_prob (float):        Dropout probability in liner layers\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        self.attention_ = self_attention_layer(dims_embd)\n",
    "        \n",
    "        self.layer_norm1_ = nn.LayerNorm(dims_embd)\n",
    "        self.layer_norm2_ = nn.LayerNorm(dims_embd)\n",
    "        \n",
    "        self.ffnn_ = nn.Sequential(\n",
    "            nn.Linear(dims_embd, num_hidden_nodes_ffnn),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden_nodes_ffnn, dims_embd)\n",
    "        )\n",
    "        self.droput_ops_ = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.dims_embd_ = dims_embd\n",
    "        self.num_hidden_nodes_ffnn_ = num_hidden_nodes_ffnn\n",
    "        self.dropout_prob_ = dropout_prob\n",
    "        \n",
    "        \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "    )->Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the transformer block\n",
    "        \n",
    "        Imput:\n",
    "            - x (torch tensor): Input data\n",
    "            \n",
    "        Output:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        attn_out = self.attention_(x)\n",
    "        x=self.layer_norm1_(x+self.droput_ops_(attn_out))\n",
    "        ffn_out = self.ffnn_(x)\n",
    "        x=self.layer_norm2_(x+self.droput_ops_(ffn_out))\n",
    "    \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "        \n",
    "        return x\n",
    "        \n",
    "class transformer_encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer encoder module\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dims_embd: int,\n",
    "        num_hidden_nodes_ffnn: int = 2048,\n",
    "        dropout_prob: float = 0.0,\n",
    "        num_layers_encoder: int = 2\n",
    "    )->None:\n",
    "        \"\"\"\n",
    "        Transformer encoder class initialization\n",
    "        \n",
    "        Inpout:\n",
    "            - dims_embd (int):             Embedding dimension\n",
    "            - num_hidden_nodes_ffnn (int): Number of neurons in the fed-forward layer\n",
    "            - dropout_prob (float):        Dropout probability in liner layers\n",
    "            - num_layers_encoder (int):    Number encoder blocks\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        self.trs_endr_blocks_ = nn.ModuleList(\n",
    "            [\n",
    "                transformer_block_encoder(dims_embd, num_hidden_nodes_ffnn, dropout_prob) for _ in range(num_layers_encoder)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.num_layers_encoder_ = num_layers_encoder\n",
    "        \n",
    "        \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "    )->Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the transformer encoder\n",
    "        \n",
    "        Imput:\n",
    "            - x (torch tensor): Input data\n",
    "            \n",
    "        Output:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        for layer in self.trs_endr_blocks_:\n",
    "            x = layer(x)\n",
    "                    \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class cross_attention_layer(nn.Module):\n",
    "    \"\"\"\n",
    "    Cross attention layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dims_embd: int,\n",
    "    )->None:\n",
    "        \"\"\"\n",
    "        Cross attention class initialization\n",
    "        \n",
    "        Inpout:\n",
    "            - dims_embd (int): Embedding dimension\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        \n",
    "        self.W_q_ = nn.Linear(dims_embd, dims_embd)\n",
    "        self.W_k_ = nn.Linear(dims_embd, dims_embd)\n",
    "        self.W_v_ = nn.Linear(dims_embd, dims_embd)\n",
    "        \n",
    "        self.dims_embd_ = dims_embd\n",
    "        \n",
    "        \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        x: Tensor,\n",
    "        y: Tensor\n",
    "    )->Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the cross-attention layer\n",
    "        \n",
    "        Imput:\n",
    "            - x (torch tensor): Input encoder data\n",
    "            - y (torch tensor): Input decoder data\n",
    "            \n",
    "        Output:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        Q=self.W_q_(y)\n",
    "        K=self.W_k_(x)\n",
    "        V=self.W_v_(x)\n",
    "\n",
    "        attn_scores=torch.matmul(Q,K.transpose(-2,-1))/torch.sqrt(torch.tensor(self.dims_embd_))\n",
    "        attn_weights=F.softmax(attn_scores,dim=-1)\n",
    "        y=torch.matmul(attn_weights,V)\n",
    "\n",
    "        \n",
    "        \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "    \n",
    "        return y\n",
    "    \n",
    "\n",
    "class transformer_block_decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer single decoder block\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dims_embd: int,\n",
    "        num_hidden_nodes_ffnn: int = 2048,\n",
    "        dropout_prob: float = 0.0\n",
    "    )->None:\n",
    "        \"\"\"\n",
    "        Transformer single block class initialization\n",
    "        \n",
    "        Inpout:\n",
    "            - dims_embd (int):             Embedding dimension\n",
    "            - num_hidden_nodes_ffnn (int): Number of neurons in the fed-forward layer\n",
    "            - dropout_prob (float):        Dropout probability in liner layers\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        \n",
    "        self.attention_ = self_attention_layer(dims_embd)\n",
    "        self.cross_attention_ = cross_attention_layer(dims_embd)\n",
    "        \n",
    "        self.layer_norm1_ = nn.LayerNorm(dims_embd)\n",
    "        self.layer_norm2_ = nn.LayerNorm(dims_embd)\n",
    "        self.layer_norm3_ = nn.LayerNorm(dims_embd)\n",
    "        \n",
    "        self.ffnn_ = nn.Sequential(\n",
    "            nn.Linear(dims_embd, num_hidden_nodes_ffnn),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden_nodes_ffnn, dims_embd)\n",
    "        )\n",
    "        self.droput_ops_ = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.dims_embd_ = dims_embd\n",
    "        self.num_hidden_nodes_ffnn_ = num_hidden_nodes_ffnn\n",
    "        self.dropout_prob_ = dropout_prob\n",
    "        \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        y: Tensor\n",
    "    )->Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the transformer block\n",
    "        \n",
    "        Imput:\n",
    "            - x (torch tensor): Input encoder data\n",
    "            - y (torch tensor): Input decoder data\n",
    "            \n",
    "        Output:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        self_attn_out = self.attention_(y)\n",
    "        y=self.layer_norm1_(y+self.droput_ops_(self_attn_out))\n",
    "        cross_attn_out = self.cross_attention_(x, y)\n",
    "        y=self.layer_norm2_(y+self.droput_ops_(cross_attn_out))\n",
    "        ffn_out = self.ffnn_(y)\n",
    "        y=self.layer_norm3_(y+self.droput_ops_(ffn_out))\n",
    "        \n",
    "        \n",
    "    \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "class transformer_decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer decoder module\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dims_embd: int,\n",
    "        num_hidden_nodes_ffnn: int = 2048,\n",
    "        dropout_prob: float = 0.0,\n",
    "        num_layers_decoder: int = 2\n",
    "    )->None:\n",
    "        \"\"\"\n",
    "        Transformer decoder class initialization\n",
    "        \n",
    "        Inpout:\n",
    "            - dims_embd (int):             Embedding dimension\n",
    "            - num_hidden_nodes_ffnn (int): Number of neurons in the fed-forward layer\n",
    "            - dropout_prob (float):        Dropout probability in liner layers\n",
    "            - num_layers_decoder (int):    Number decoder blocks\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        self.trs_dcdr_blocks_ = nn.ModuleList(\n",
    "            [\n",
    "                transformer_block_decoder(dims_embd, num_hidden_nodes_ffnn, dropout_prob) for _ in range(num_layers_decoder)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.num_layers_decoder_ = num_layers_decoder\n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        y: Tensor\n",
    "    )->Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for the transformer encoder\n",
    "        \n",
    "        Imput:\n",
    "            - x (torch tensor): Input encoder data\n",
    "            - y (torch tensor): Input decoder data\n",
    "            \n",
    "        Output:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ############################################################################\n",
    "        #                             Your code will be here                       #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        for layer in self.trs_dcdr_blocks_:\n",
    "            y= layer(x, y)\n",
    "        \n",
    "        \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #                             End of your code                             #\n",
    "        ############################################################################\n",
    "        \n",
    "        return y\n",
    "        \n",
    "       \n",
    "    \n",
    "dims_embd = 10\n",
    "num_data_points = 100\n",
    "batch_size = 5\n",
    "num_hidden_nodes_ffnn = 1024\n",
    "dropout_prob = 0.2\n",
    "num_layers_encoder = 2\n",
    "\n",
    "x = torch.rand(batch_size, num_data_points, dims_embd)\n",
    "y = torch.rand(batch_size, num_data_points, dims_embd)\n",
    "\n",
    "# Test Self-attention layer and its input output size  \n",
    "print('='*70)\n",
    "model_self_attention_layer = self_attention_layer(dims_embd)\n",
    "print('Self-attention layer models is: \\n{}' .format(model_self_attention_layer))\n",
    "print('-'*70)\n",
    "\n",
    "y_bar = model_self_attention_layer(x)\n",
    "print('Self-attention layer input size: {}' .format(x.shape))\n",
    "print('Self-attention layer output size: {}' .format(y_bar.shape))\n",
    "print('-'*70)\n",
    "        \n",
    "# Test Transformer encoder block input output size \n",
    "print('='*70)\n",
    "model_transformer_block_encoder = transformer_block_encoder(dims_embd, num_hidden_nodes_ffnn, dropout_prob)\n",
    "print('Transformer block models is: \\n{}' .format(model_transformer_block_encoder))\n",
    "print('-'*70)\n",
    "print('Transformer block models summary:')\n",
    "print('-'*70)\n",
    "summary(model_transformer_block_encoder, (num_data_points, dims_embd, ), device=str(\"cpu\"))\n",
    "print('-'*70)\n",
    "\n",
    "y_bar = model_transformer_block_encoder(x)\n",
    "print('Transformer block input size: {}' .format(x.shape))\n",
    "print('Transformer block output size: {}' .format(y_bar.shape))  \n",
    "print('-'*70)\n",
    "\n",
    "# Test Transformer encoder input output size \n",
    "print('='*70)\n",
    "model_transformer_encoder = transformer_encoder(dims_embd, num_hidden_nodes_ffnn, dropout_prob, num_layers_encoder)\n",
    "print('Transformer encoder models is: \\n{}' .format(model_transformer_encoder))\n",
    "print('-'*70)\n",
    "print('Transformer encoder models summary:')\n",
    "print('-'*70)\n",
    "summary(model_transformer_encoder, (num_data_points, dims_embd, ), device=str(\"cpu\"))\n",
    "print('-'*70)\n",
    "\n",
    "y_bar = model_transformer_encoder(x)\n",
    "print('Transformer encoder input size: {}' .format(x.shape))\n",
    "print('Transformer encoder output size: {}' .format(y_bar.shape))  \n",
    "print('-'*70)\n",
    "\n",
    "# Test Cross-attention layer and its input output size  \n",
    "print('='*70)\n",
    "model_cross_attention_layer = cross_attention_layer(dims_embd)\n",
    "print('Cross-attention layer models is: \\n{}' .format(model_cross_attention_layer))\n",
    "print('-'*70)\n",
    "\n",
    "y_bar = model_cross_attention_layer(x, y)\n",
    "print('Cross-attention layer input size: {}' .format(x.shape))\n",
    "print('Cross-attention layer output size: {}' .format(y_bar.shape))\n",
    "print('-'*70)\n",
    "\n",
    "# Test Transformer decoder block input output size \n",
    "print('='*70)\n",
    "model_transformer_block_decoder = transformer_block_decoder(dims_embd, num_hidden_nodes_ffnn, dropout_prob)\n",
    "print('Transformer decoder block models is: \\n{}' .format(model_transformer_block_decoder))\n",
    "print('-'*70)\n",
    "print('Transformer decoder block models summary:')\n",
    "print('-'*70)\n",
    "summary(model_transformer_block_decoder, [(num_data_points, dims_embd, ), (num_data_points, dims_embd, )], device=str(\"cpu\"))\n",
    "print('-'*70)\n",
    "\n",
    "y_bar = model_transformer_block_decoder(x, y)\n",
    "print('Transformer block input size: {}' .format(x.shape))\n",
    "print('Transformer block output size: {}' .format(y_bar.shape))  \n",
    "print('-'*70)\n",
    "\n",
    "# Test Transformer decoder input output size \n",
    "print('='*70)\n",
    "model_transformer_decoder = transformer_decoder(dims_embd, num_hidden_nodes_ffnn, dropout_prob, num_layers_encoder)\n",
    "print('Transformer decoder models is: \\n{}' .format(model_transformer_decoder))\n",
    "print('-'*70)\n",
    "print('Transformer decoder models summary:')\n",
    "print('-'*70)\n",
    "summary(model_transformer_decoder, [(num_data_points, dims_embd, ), (num_data_points, dims_embd, )], device=str(\"cpu\"))\n",
    "print('-'*70)\n",
    "\n",
    "y_bar = model_transformer_decoder(x, y)\n",
    "print('Transformer decoder input size: {}' .format(x.shape))\n",
    "print('Transformer decoder output size: {}' .format(y_bar.shape))  \n",
    "print('-'*70)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6901087",
   "metadata": {},
   "source": [
    "## **Language Translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4fe3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ebd6639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5d9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_path=\"./bn-en.txt/OpenSubtitles.bn-en.en\"\n",
    "bn_path=\"./bn-en.txt/OpenSubtitles.bn-en.bn\"\n",
    "with open(en_path, 'r', encoding='utf-8') as f:\n",
    "    eng=f.read().splitlines()\n",
    "\n",
    "with open(bn_path,'r', encoding='utf-8') as f:\n",
    "    ben=f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d3d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(eng) == len(ben)\n",
    "df = pd.DataFrame({'english':eng,'bengali':ben})\n",
    "df = df.dropna()\n",
    "df.to_csv('./translation.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8695f238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.419830051928578\n"
     ]
    }
   ],
   "source": [
    "length = df['english'].str.len().mean()\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e901065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./translation.csv')\n",
    "combined_sentences = df['english'].tolist() + df['bengali'].tolist()\n",
    "with open('./combined.txt', 'w', encoding='utf-8') as f:\n",
    "    for sentence in combined_sentences:\n",
    "        f.write(sentence.strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79fcf903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, sentences):\n",
    "        self.word_to_idx = {'<pad>': 0, '<unk>': 1, '<start>': 2, '<end>': 3}\n",
    "        self.idx_to_word = {v: k for k, v in self.word_to_idx.items()}\n",
    "        \n",
    "        for sent in sentences:\n",
    "            for word in sent.split():\n",
    "                if word not in self.word_to_idx:\n",
    "                    new_idx = len(self.word_to_idx)\n",
    "                    self.word_to_idx[word] = new_idx\n",
    "                    self.idx_to_word[new_idx] = word\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.word_to_idx)\n",
    "src_vocab = Vocab(eng)\n",
    "tgt_vocab = Vocab(ben)\n",
    "\n",
    "def pad_batch(sequences,pad_val=0):\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        padding = torch.full((max_len - len(seq),), pad_val, dtype=seq.dtype)\n",
    "        padded.append(torch.cat([seq, padding]))\n",
    "    return torch.stack(padded)\n",
    "\n",
    "def batch_collator(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    return pad_batch(src_batch), pad_batch(tgt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec79a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelDataset(Dataset):\n",
    "    def __init__(self, src_texts, tgt_texts, src_vocab, tgt_vocab, max_len=75):\n",
    "        self.src_texts = src_texts\n",
    "        self.tgt_texts = tgt_texts\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.src_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src_tokens = [self.src_vocab.word_to_idx.get(word, 1) \n",
    "                     for word in self.src_texts[idx].split()[:self.max_len]]\n",
    "        tgt_tokens = [self.tgt_vocab.word_to_idx.get(word, 1)\n",
    "                     for word in self.tgt_texts[idx].split()[:self.max_len]]\n",
    "        src_tokens = [2] + src_tokens + [3]\n",
    "        tgt_tokens = [2] + tgt_tokens + [3]\n",
    "        \n",
    "        return torch.LongTensor(src_tokens), torch.LongTensor(tgt_tokens)\n",
    "\n",
    "dataset = ParallelDataset(ben, eng, src_vocab, tgt_vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=batch_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b53451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(nn.Module):\n",
    "    def __init__(self,src_vocab_size,tgt_vocab_size,emb_dim=512,dim_fffn=1024,num_layers=2,dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.src_embed = nn.Embedding(src_vocab_size, emb_dim)\n",
    "        self.tgt_embed = nn.Embedding(tgt_vocab_size, emb_dim)\n",
    "        \n",
    "        self.encoder = transformer_encoder(emb_dim,dim_fffn,dropout,num_layers)        \n",
    "        self.decoder = transformer_decoder(emb_dim,dim_fffn,dropout,num_layers)        \n",
    "\n",
    "        \n",
    "        self.output_layer = nn.Linear(emb_dim, tgt_vocab_size)\n",
    "\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        src_emb = self.src_embed(src)\n",
    "        tgt_emb = self.tgt_embed(tgt)\n",
    "        encoded = self.encoder(src_emb)\n",
    "        decoded = self.decoder(encoded, tgt_emb)\n",
    "        \n",
    "        return self.output_layer(decoded)\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=Translator(src_vocab.size(),tgt_vocab.size()).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters())\n",
    "loss_fn=nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b8301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 2.5899\n",
      "Epoch 2, Avg Loss: 2.5807\n",
      "Epoch 3, Avg Loss: 2.5432\n",
      "Epoch 4, Avg Loss: 2.5191\n",
      "Epoch 5, Avg Loss: 2.6004\n",
      "Epoch 6, Avg Loss: 2.5166\n",
      "Epoch 7, Avg Loss: 2.3904\n",
      "Epoch 8, Avg Loss: 2.4849\n",
      "Epoch 9, Avg Loss: 2.6157\n",
      "Epoch 10, Avg Loss: 2.5555\n",
      "Epoch 11, Avg Loss: 2.5108\n",
      "Epoch 12, Avg Loss: 2.2848\n",
      "Epoch 13, Avg Loss: 2.2533\n",
      "Epoch 14, Avg Loss: 2.2230\n",
      "Epoch 15, Avg Loss: 2.1461\n",
      "Epoch 16, Avg Loss: 2.1333\n",
      "Epoch 17, Avg Loss: 2.2824\n",
      "Epoch 18, Avg Loss: 2.2562\n",
      "Epoch 19, Avg Loss: 2.2959\n",
      "Epoch 20, Avg Loss: 2.3495\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_model(model, dataloader, n_epochs=20):\n",
    "    model.train()\n",
    "    epoch_losses=[]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss=0\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt=src.to(device), tgt.to(device)\n",
    "            outputs=model(src, tgt[:, :-1])\n",
    "            loss=loss_fn(outputs.reshape(-1, outputs.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss+=loss.item()\n",
    "        \n",
    "        avg_loss=total_loss / len(dataloader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "        print(f'Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    plt.plot(range(1, n_epochs+1), epoch_losses, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "train_model(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcdd35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
